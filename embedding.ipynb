{
 "cells": [
  {
   "cell_type": "code",
   "id": "e38d66e24aa30475",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T07:53:13.374867Z",
     "start_time": "2025-04-17T07:53:13.341842Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from llama_index.core import Document, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core.extractors import BaseExtractor\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
    "import nest_asyncio\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "\n",
    "class UnifiedEmbedding:\n",
    "    \"\"\"统一嵌入模型接口\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type: str = \"dashscope\",\n",
    "        model_name: str = \"text-embedding-v2\",\n",
    "        dashscope_text_type: str = \"document\",\n",
    "        api_key: str = None,\n",
    "        base_url: str = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_type: 模型类型 (openai/dashscope)\n",
    "            model_name: 模型名称\n",
    "            dashscope_text_type: DashScope文本类型\n",
    "            api_key: API密钥\n",
    "            base_url: 服务地址\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if model_type == \"dashscope\":\n",
    "            self.embedder = DashScopeEmbedding(\n",
    "                model_name=model_name,\n",
    "                text_type=dashscope_text_type,\n",
    "                api_key=api_key\n",
    "            )\n",
    "        else:\n",
    "            self.embedder = OpenAIEmbedding(\n",
    "                # openai 默认的嵌入模型\n",
    "                # model: str = OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002,\n",
    "                # model=model_name,\n",
    "                api_key=api_key,\n",
    "                api_base=base_url\n",
    "            )\n",
    "\n",
    "    def get_embed_model(self):\n",
    "        return self.embedder\n",
    "\n",
    "class CustomExtractor(BaseExtractor):\n",
    "    \"\"\"统一元数据提取器\"\"\"\n",
    "    async def aextract(self, nodes) -> List[Dict]:\n",
    "        return [{\n",
    "            \"title\": node.metadata[\"title\"],\n",
    "            \"source\": node.metadata[\"source\"],\n",
    "            \"published_at\": node.metadata[\"published_at\"]\n",
    "        } for node in nodes]\n",
    "\n",
    "def build_vector_indices(\n",
    "    input_path: str,\n",
    "    output_dir: str,\n",
    "    model_type: str = \"dashscope\",\n",
    "    model_name: str = \"text-embedding-v2\",\n",
    "    chunk_size: int = 256,\n",
    "    chunk_overlap: int = 20,\n",
    "    api_key: str = None,\n",
    "    base_url: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    统一索引构建函数\n",
    "    \n",
    "    Args:\n",
    "        input_path: 输入路径（文件或文件夹）\n",
    "        output_dir: 输出目录\n",
    "        model_type: 模型类型 (openai/dashscope)\n",
    "        model_name: 模型名称\n",
    "        chunk_size: 文本分块大小\n",
    "        chunk_overlap: 分块重叠大小\n",
    "        api_key: API密钥\n",
    "        base_url: 服务地址\n",
    "    \"\"\"\n",
    "    # 初始化异步环境\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # 初始化嵌入模型\n",
    "    embed_model = UnifiedEmbedding(\n",
    "        model_type=model_type,\n",
    "        model_name=model_name,\n",
    "        api_key=api_key,\n",
    "        base_url=base_url\n",
    "    ).get_embed_model()\n",
    "\n",
    "    # 获取文件列表\n",
    "    if os.path.isdir(input_path):\n",
    "        json_files = [str(p) for p in Path(input_path).glob(\"*.json\")]\n",
    "    else:\n",
    "        json_files = [input_path]\n",
    "\n",
    "    # 处理每个文件\n",
    "    for idx, json_path in enumerate(json_files):\n",
    "        print(f\"\\n处理 {json_path} ({idx+1}/{len(json_files)})\")\n",
    "\n",
    "        # 加载数据\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            load_data = json.load(f)\n",
    "\n",
    "        # 创建文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                text=data['body'],\n",
    "                metadata={\n",
    "                    \"title\": data['title'],\n",
    "                    \"published_at\": data['published_at'],\n",
    "                    \"source\": data['source']\n",
    "                }\n",
    "            ) for data in load_data\n",
    "        ]\n",
    "\n",
    "        # 构建处理管道\n",
    "        text_splitter = SentenceSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        pipeline = IngestionPipeline(transformations=[\n",
    "            text_splitter,\n",
    "            CustomExtractor()\n",
    "        ])\n",
    "        nodes = pipeline.run(documents=documents)\n",
    "\n",
    "        # 创建存储\n",
    "        vector_store = SimpleVectorStore()\n",
    "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "        # 构建索引\n",
    "        index = VectorStoreIndex(\n",
    "            nodes,\n",
    "            storage_context=storage_context,\n",
    "            embed_model=embed_model,\n",
    "            show_progress=True\n",
    "        )\n",
    "\n",
    "        # 持久化存储\n",
    "        file_stem = Path(json_path).stem\n",
    "        persist_dir = os.path.join(output_dir, f\"index_{file_stem}\")\n",
    "        os.makedirs(persist_dir, exist_ok=True)\n",
    "        storage_context.persist(persist_dir=persist_dir)\n",
    "        print(f\"Index persisted at: {persist_dir}\")\n",
    "        \n",
    "def build_bm25_indices(\n",
    "    input_path: str,\n",
    "    output_dir: str,\n",
    "    chunk_size: int = 256,\n",
    "    chunk_overlap: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    统一索引构建函数\n",
    "    Args:\n",
    "        input_path: 输入路径（文件或文件夹）\n",
    "        output_dir: 输出目录\n",
    "        chunk_size:\n",
    "        chunk_overlap:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化异步环境\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    # 获取文件列表\n",
    "    if os.path.isdir(input_path):\n",
    "        json_files = [str(p) for p in Path(input_path).glob(\"*.json\")]\n",
    "    else:\n",
    "        json_files = [input_path]\n",
    "\n",
    "    # 处理每个文件\n",
    "    for idx, json_path in enumerate(json_files):\n",
    "        print(f\"\\n处理 {json_path} ({idx+1}/{len(json_files)})\")\n",
    "\n",
    "        # 加载数据\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            load_data = json.load(f)\n",
    "\n",
    "        # 创建文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                text=data['body'],\n",
    "                metadata={\n",
    "                    \"title\": data['title'],\n",
    "                    \"published_at\": data['published_at'],\n",
    "                    \"source\": data['source']\n",
    "                }\n",
    "            ) for data in load_data\n",
    "        ]\n",
    "\n",
    "        # 构建处理管道\n",
    "        text_splitter = SentenceSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        pipeline = IngestionPipeline(transformations=[\n",
    "            text_splitter,\n",
    "            CustomExtractor()\n",
    "        ])\n",
    "        nodes = pipeline.run(documents=documents)\n",
    "        \n",
    "        bm25retriever = BM25Retriever.from_defaults(nodes=nodes)\n",
    "        file_stem = Path(json_path).stem\n",
    "        persist_dir = os.path.join(output_dir, f\"index_{file_stem}\")\n",
    "        os.makedirs(persist_dir, exist_ok=True)\n",
    "        bm25retriever.persist(path=persist_dir)\n",
    "        print(f\"Index persisted at: {persist_dir}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DashScope 使用示例\n",
    "build_vector_indices(\n",
    "    input_path=\"splits/balance_3\",\n",
    "    output_dir=\"./embeddings/dashscope/balance_3\",\n",
    "    model_type=\"dashscope\",\n",
    "    model_name=\"text-embedding-v2\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")"
   ],
   "id": "ff3cb52831d6b891",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# OpenAI 使用示例\n",
    "build_vector_indices(\n",
    "    input_path=\"splits/balance_3\",\n",
    "    output_dir=\"./embeddings/openai/balance_3\",\n",
    "    model_type=\"openai\",\n",
    "    model_name=\"text-embedding-3-large\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")"
   ],
   "id": "7b0539f7d2ede131",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:51:32.033762Z",
     "start_time": "2025-04-17T08:51:21.073491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "build_bm25_indices(\n",
    "    input_path=\"splits/balance_2\",\n",
    "    output_dir=\"embeddings/bm25/balance_2\",\n",
    ")"
   ],
   "id": "c180c785aee1006",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理 splits\\balance_2\\group_0.json (1/2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Finding newlines for mmindex:   0%|          | 0.00/12.1M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc984142ba22464199cee9cabee063c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index persisted at: embeddings/bm25/balance_2\\index_group_0\n",
      "\n",
      "处理 splits\\balance_2\\group_1.json (2/2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Finding newlines for mmindex:   0%|          | 0.00/10.8M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a181107f93974fa5a9dfe6d54bcb3028"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index persisted at: embeddings/bm25/balance_2\\index_group_1\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
